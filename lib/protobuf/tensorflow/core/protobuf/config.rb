# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: tensorflow/core/protobuf/config.proto

require 'google/protobuf'

require 'tensorflow/core/framework/cost_graph'
require 'tensorflow/core/framework/step_stats'
Google::Protobuf::DescriptorPool.generated_pool.build do
  add_message "tensorflow.GPUOptions" do
    optional :per_process_gpu_memory_fraction, :double, 1
    optional :allocator_type, :string, 2
    optional :deferred_deletion_bytes, :int64, 3
    optional :allow_growth, :bool, 4
  end
  add_message "tensorflow.OptimizerOptions" do
    optional :do_common_subexpression_elimination, :bool, 1
    optional :do_constant_folding, :bool, 2
    optional :do_function_inlining, :bool, 4
    optional :opt_level, :enum, 3, "tensorflow.OptimizerOptions.Level"
  end
  add_enum "tensorflow.OptimizerOptions.Level" do
    value :L1, 0
    value :L0, -1
  end
  add_message "tensorflow.GraphOptions" do
    optional :enable_recv_scheduling, :bool, 2
    optional :optimizer_options, :message, 3, "tensorflow.OptimizerOptions"
    optional :build_cost_model, :int64, 4
    optional :infer_shapes, :bool, 5
    optional :place_pruned_graph, :bool, 6
  end
  add_message "tensorflow.ThreadPoolOptionProto" do
    optional :num_threads, :int32, 1
  end
  add_message "tensorflow.ConfigProto" do
    map :device_count, :string, :int32, 1
    optional :intra_op_parallelism_threads, :int32, 2
    optional :inter_op_parallelism_threads, :int32, 5
    optional :use_per_session_threads, :bool, 9
    repeated :session_inter_op_thread_pool, :message, 12, "tensorflow.ThreadPoolOptionProto"
    optional :placement_period, :int32, 3
    repeated :device_filters, :string, 4
    optional :gpu_options, :message, 6, "tensorflow.GPUOptions"
    optional :allow_soft_placement, :bool, 7
    optional :log_device_placement, :bool, 8
    optional :graph_options, :message, 10, "tensorflow.GraphOptions"
    optional :operation_timeout_in_ms, :int64, 11
  end
  add_message "tensorflow.RunOptions" do
    optional :trace_level, :enum, 1, "tensorflow.RunOptions.TraceLevel"
    optional :timeout_in_ms, :int64, 2
    optional :inter_op_thread_pool, :int32, 3
  end
  add_enum "tensorflow.RunOptions.TraceLevel" do
    value :NO_TRACE, 0
    value :SOFTWARE_TRACE, 1
    value :HARDWARE_TRACE, 2
    value :FULL_TRACE, 3
  end
  add_message "tensorflow.RunMetadata" do
    optional :step_stats, :message, 1, "tensorflow.StepStats"
    optional :cost_graph, :message, 2, "tensorflow.CostGraphDef"
  end
end

module Tensorflow
  GPUOptions = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.GPUOptions").msgclass
  OptimizerOptions = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.OptimizerOptions").msgclass
  OptimizerOptions::Level = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.OptimizerOptions.Level").enummodule
  GraphOptions = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.GraphOptions").msgclass
  ThreadPoolOptionProto = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.ThreadPoolOptionProto").msgclass
  ConfigProto = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.ConfigProto").msgclass
  RunOptions = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.RunOptions").msgclass
  RunOptions::TraceLevel = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.RunOptions.TraceLevel").enummodule
  RunMetadata = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.RunMetadata").msgclass
end
